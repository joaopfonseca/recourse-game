{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbc70b-72dc-4f23-96f9-648d2e5a4b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlresearch.utils import set_matplotlib_style\n",
    "from recgame.environments import FairEnvironment\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_matplotlib_style(16)\n",
    "\n",
    "# Some variables to define the problem\n",
    "BIAS_FACTOR = 3\n",
    "RNG_SEED = 55\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "N_CONTINUOUS = 2\n",
    "N_AGENTS = 100\n",
    "\n",
    "# NOTE: Categorical feature will be the \"groups\" variable; immutable + categorical\n",
    "\n",
    "# Environment variables\n",
    "N_LOANS = 10\n",
    "ADAPTATION = .5\n",
    "NEW_AGENTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8afd6-6648-4232-9fb9-03250d1ae0df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NFeatureRecourse ignoring categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf9868-2b2b-4b2b-8cda-63dd90e0e083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "from recgame.recourse.base import BaseRecourse\n",
    "\n",
    "\n",
    "class NFeatureRecourse(BaseRecourse):\n",
    "    \"\"\"TODO: Add documentation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        n_features: int = None,\n",
    "        threshold=0.5,\n",
    "        categorical: Union[list, np.ndarray] = None,\n",
    "        immutable: Union[list, np.ndarray] = None,\n",
    "        step_direction: dict = None,\n",
    "        y_desired: Union[int, str] = 1,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            threshold=threshold,\n",
    "            categorical=categorical,\n",
    "            immutable=immutable,\n",
    "            step_direction=step_direction,\n",
    "            y_desired=y_desired,\n",
    "        )\n",
    "\n",
    "        # if categorical is not None and categorical != []:\n",
    "        #     raise TypeError(\n",
    "        #         \"NFeatureRecourse does not work with categorical features. Consider \"\n",
    "        #         \"using a different recourse method.\"\n",
    "        #     )\n",
    "\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def _counterfactual(self, agent, action_set):\n",
    "        agent_original = agent.copy()\n",
    "\n",
    "        # Do not change if the agent is over the threshold\n",
    "        if self.model.predict_proba(agent.to_frame().T)[0, -1] >= self.threshold:\n",
    "            return agent_original\n",
    "\n",
    "        categorical_vals = agent_original[self.categorical].values\n",
    "        agent = agent_original.drop(self.categorical).copy()\n",
    "\n",
    "        intercept, coefficients, model = self._get_coefficients()\n",
    "\n",
    "        # Get base vector\n",
    "        base_vector = coefficients.copy().squeeze()\n",
    "        n_features = (\n",
    "            base_vector.shape[0] if self.n_features is None else self.n_features\n",
    "        )\n",
    "\n",
    "        is_usable = np.array(\n",
    "            [\n",
    "                action_set[col].step_direction in [np.sign(coeff), 0]\n",
    "                and action_set[col].actionable\n",
    "                for col, coeff in zip(agent.index, base_vector)\n",
    "            ]\n",
    "        )\n",
    "        base_vector[~is_usable] = 0\n",
    "\n",
    "        # Use features with highest contribution towards the threshold\n",
    "        rejected_features = np.argsort(np.abs(base_vector))[:-n_features]\n",
    "        base_vector[rejected_features] = 0\n",
    "\n",
    "        base_vector = base_vector / np.linalg.norm(base_vector)\n",
    "        multiplier = (-intercept - np.dot(agent.values, coefficients.T)) / np.dot(\n",
    "            base_vector, coefficients.T\n",
    "        )\n",
    "        counterfactual = agent + multiplier * base_vector\n",
    "                        \n",
    "        lb, ub = np.array(action_set.lb), np.array(action_set.ub)\n",
    "        \n",
    "        lb = lb[action_set.df.name.values != self.categorical]\n",
    "        ub = ub[action_set.df.name.values != self.categorical]\n",
    "\n",
    "        # Check if base_vector adjustments are not generating invalid counterfactuals\n",
    "        for i in range(agent.shape[0]):\n",
    "            # Adjust vector according to features' bounds\n",
    "            lb_valid = counterfactual >= lb\n",
    "            ub_valid = counterfactual <= ub\n",
    "\n",
    "            if lb_valid.all() and ub_valid.all():\n",
    "                break\n",
    "\n",
    "            if not lb_valid.all():\n",
    "                # Fix values to its lower bound\n",
    "                idx = np.where(~lb_valid)[0]\n",
    "                agent[idx] = lb[idx]\n",
    "                base_vector[idx] = 0\n",
    "\n",
    "            if not ub_valid.all():\n",
    "                # Fix values to its upper bound\n",
    "                idx = np.where(~ub_valid)[0]\n",
    "                agent[idx] = ub[idx]\n",
    "                base_vector[idx] = 0\n",
    "\n",
    "            if (base_vector == 0).all():\n",
    "                # All max/min boundaries have been met.\n",
    "                counterfactual = agent\n",
    "            else:\n",
    "                \n",
    "                # Redefine counterfactual after adjusting the base vector\n",
    "                base_vector = base_vector / np.linalg.norm(base_vector)\n",
    "                multiplier = (\n",
    "                    -intercept - np.dot(agent.values, coefficients.T)\n",
    "                ) / np.dot(base_vector, coefficients.T)\n",
    "                counterfactual = agent + multiplier * base_vector\n",
    "\n",
    "        lb_valid = counterfactual >= lb\n",
    "        ub_valid = counterfactual <= ub\n",
    "        if not (lb_valid.all() and ub_valid.all()):\n",
    "            warnings.warn(\n",
    "                \"Could not generate a counterfactual to reach the desired threshold.\"\n",
    "            )\n",
    "\n",
    "            \n",
    "        for cat_feat, value in zip(self.categorical, categorical_vals):\n",
    "            counterfactual[cat_feat] = value\n",
    "\n",
    "\n",
    "        return counterfactual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c9bc4-0d89-44fd-8b81-b2582a7d62bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29063079-1419-4422-b6d9-a3065d401245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(n_agents=10_000, n_continuous=2, bias_factor=0, mean=0, std=1/4, random_state=None):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    groups = pd.Series(rng.binomial(1,.5, n_agents), name=\"groups\")\n",
    "    counts = Counter(groups)\n",
    "    continuous_cols = [f\"f{i}\" for i in range(n_continuous)]\n",
    "    \n",
    "    # Generate the input dataset\n",
    "    X_0 = pd.DataFrame(\n",
    "        rng.normal(loc=mean, scale=std, size=(counts[0], n_continuous)),\n",
    "        index=groups[groups == 0].index,\n",
    "        columns=continuous_cols,\n",
    "    )\n",
    "\n",
    "    X_1 = pd.DataFrame(\n",
    "        rng.normal(loc=mean+bias_factor*std, scale=std, size=(counts[1], n_continuous)),\n",
    "        index=groups[groups == 1].index,\n",
    "        columns=continuous_cols,\n",
    "    )\n",
    "\n",
    "    X = pd.concat([X_0, X_1]).sort_index()\n",
    "    return MinMaxScaler().fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317bc09-18c3-4b55-a004-78ac24322b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler(\n",
    "    n_agents=10_000, \n",
    "    n_continuous=N_CONTINUOUS, \n",
    "    bias_factor=BIAS_FACTOR, \n",
    "    random_state=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d5e89-9535-459a-b01a-76945b2e745b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def biased_data_generator(n_agents, n_continuous=2, bias_factor=0, mean=0, std=1/4, scaler=None, random_state=None):\n",
    "    \"\"\"\n",
    "    groups feature: \n",
    "    - 0 -> Disadvantaged group\n",
    "    - 1 -> Advantaged group\n",
    "    \n",
    "    ``bias_factor`` varies between [0, 1], 0 is completely unbiased, 1 is fully biased.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    groups = pd.Series(rng.binomial(1,.5, n_agents), name=\"groups\")\n",
    "    counts = Counter(groups)\n",
    "    continuous_cols = [f\"f{i}\" for i in range(n_continuous)]\n",
    "\n",
    "    # Generate the input dataset\n",
    "    X_0 = pd.DataFrame(\n",
    "        rng.normal(loc=mean, scale=std, size=(counts[0], n_continuous)),\n",
    "        index=groups[groups == 0].index,\n",
    "        columns=continuous_cols,\n",
    "    )\n",
    "\n",
    "    X_1 = pd.DataFrame(\n",
    "        rng.normal(loc=mean+bias_factor*std, scale=std, size=(counts[1], n_continuous)),\n",
    "        index=groups[groups == 1].index,\n",
    "        columns=continuous_cols,\n",
    "    )\n",
    "\n",
    "    X = pd.concat([X_0, X_1]).sort_index()\n",
    "    \n",
    "    # TEST: scale continuous features\n",
    "    if scaler is not None:\n",
    "        X.loc[:,:] = scaler.transform(X)\n",
    "    \n",
    "    X = pd.concat([X, groups], axis=1)\n",
    "    X = np.clip(X, 0, 1)\n",
    "    \n",
    "    # Generate the target\n",
    "    p0 = 1 / (2 + 2*bias_factor)\n",
    "    p1 = 1 - p0\n",
    "\n",
    "    y0 = rng.binomial(1, p0, counts[0])\n",
    "    y1 = rng.binomial(1, p1, counts[1])\n",
    "    \n",
    "    y = pd.concat(\n",
    "        [\n",
    "            pd.Series((y0 if val==0 else y1), index=group.index) \n",
    "            for val, group in X.groupby(\"groups\")\n",
    "        ]\n",
    "    ).sort_index()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef137d3f-fe1f-4bbb-a0dd-52b058db1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_biased_data_generator(n_agents):\n",
    "    return biased_data_generator(n_agents, n_continuous=N_CONTINUOUS, bias_factor=BIAS_FACTOR, scaler=scaler, random_state=rng)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c7c00-43aa-4a67-b0e8-c9872fd07ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IgnoreGroupLR(LogisticRegression):\n",
    "    def __init__(self, ignore_feature=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ignore_feature = ignore_feature\n",
    "    \n",
    "    def _get_X(self, X):\n",
    "        return X.copy() if self.ignore_feature is None else X.drop(columns=self.ignore_feature)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"NOTE: X must be a pandas dataframe.\"\"\"\n",
    "        super().fit(self._get_X(X), y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return super().predict(self._get_X(X))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(self._get_X(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5e28e-ddf1-4ba6-a1db-56736c215f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recgame.environments._behavior_functions import ContinuousFlexible\n",
    "\n",
    "\n",
    "class ContinuousConstantCustom(ContinuousFlexible):\n",
    "    \"\"\"Applies continuous adaptation with constant effort.\"\"\"\n",
    "    bias_factor_effort_g0 = 0\n",
    "    bias_factor_effort_g1 = 0\n",
    "    \n",
    "    def effort(self, X, global_adaptation):\n",
    "        \"\"\"\n",
    "        Applies constant effort.\n",
    "\n",
    "        Returns effort rate.\n",
    "        \"\"\"\n",
    "        # Fetch environment variables\n",
    "        rng = self.environment._rng\n",
    "\n",
    "        current_effort = (\n",
    "            self.environment.effort_ if hasattr(self.environment, \"effort_\") else None\n",
    "        )\n",
    "\n",
    "        df_new = (\n",
    "            self.environment._new_agents\n",
    "            if hasattr(self.environment, \"_new_agents\")\n",
    "            else X\n",
    "        )\n",
    "\n",
    "        counts = Counter(df_new[\"groups\"])\n",
    "        \n",
    "        x0 = np.abs(rng.normal(0+self.bias_factor_effort_g0, 1, counts[0]))\n",
    "        x1 = np.abs(rng.normal(0+self.bias_factor_effort_g1, 1, counts[1]))\n",
    "        \n",
    "        x = df_new[\"groups\"].copy()\n",
    "        x.loc[x==0] = x0\n",
    "        x.loc[x==1] = x1\n",
    "        x = x.values\n",
    "\n",
    "        effort_rate = x * global_adaptation / 20\n",
    "        effort_rate = pd.Series(effort_rate, index=df_new.index)\n",
    "        effort_rate = pd.concat([current_effort, effort_rate])\n",
    "\n",
    "        # return pd.Series(effort_rate, index=X.index)\n",
    "        return effort_rate\n",
    "\n",
    "    \n",
    "def behavior_function_generator(bias_factor_effort_g0, bias_factor_effort_g1):\n",
    "    behav = ContinuousConstantCustom\n",
    "    behav.bias_factor_effort_g0 = bias_factor_effort_g0\n",
    "    behav.bias_factor_effort_g1 = bias_factor_effort_g1\n",
    "    return behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a3ec5-f8d3-46e2-9ce1-55a790648ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fairness_metrics(environment, bins=10, advantaged_pop=1):\n",
    "    # Get groups\n",
    "    groups = pd.concat([environment.metadata_[step][\"X\"][\"groups\"] for step in environment.metadata_.keys()])\n",
    "    groups = groups[~groups.index.duplicated(keep='last')].sort_index()\n",
    "\n",
    "    # Get time for recourse\n",
    "    agents_info = environment.analysis.agents_info()\n",
    "    agents_info = pd.concat([agents_info, groups], axis=1)\n",
    "    agents_info[\"time_for_recourse\"] = agents_info[\"favorable_step\"] - agents_info[\"entered_step\"]\n",
    "\n",
    "    # Get fairness analysis\n",
    "    fairness_analysis = agents_info.dropna().groupby(\"groups\").mean()\n",
    "    success_rates = environment.analysis.success_rate(filter_feature=\"groups\")\n",
    "    fairness_analysis[\"avg_recourse_reliability\"] = success_rates.mean()\n",
    "\n",
    "    # Get disparity metrics\n",
    "    not_advantaged = fairness_analysis.index[fairness_analysis.index != advantaged_pop]\n",
    "    \n",
    "    if len(not_advantaged) > 1:\n",
    "        raise NotImplementedError(\"Only two groups supported.\")\n",
    "    else:\n",
    "        not_advantaged = not_advantaged[0]\n",
    "        \n",
    "    disparates = (fairness_analysis.loc[not_advantaged] / fairness_analysis.loc[advantaged_pop])\n",
    "    disparates = disparates[[\"time_for_recourse\"]]\n",
    "    disparates.index = [var for var in disparates.index + \"_disparity\"]\n",
    "    disparates[\"time_for_recourse_disparity\"] = (\n",
    "        fairness_analysis.loc[not_advantaged, \"time_for_recourse\"] \n",
    "        - fairness_analysis.loc[advantaged_pop, \"time_for_recourse\"]\n",
    "    )\n",
    "\n",
    "    # Get Equality of Opportunity\n",
    "    init_scores = environment.metadata_[0][\"score\"]\n",
    "    efforts = []\n",
    "    for step in environment.metadata_.keys():\n",
    "        if step == 0:\n",
    "            continue\n",
    "            \n",
    "        eff = (\n",
    "            environment.outcome(step=step, return_scores=True)[-1]\n",
    "            - environment.outcome(step=step-1, return_scores=True)[-1]\n",
    "        )\n",
    "        eff = eff[eff.index.isin(environment.metadata_[step][\"X\"].index)]\n",
    "        eff.fillna(0, inplace=True)\n",
    "        \n",
    "        efforts.append((step, eff))\n",
    "\n",
    "    \n",
    "    # Used to get the features to calculate EO\n",
    "    def extract_info(df):\n",
    "        avg_effort = df[\"effort\"].mean()    \n",
    "        outcome_rate = df[\"outcome\"].sum() / df.shape[0]\n",
    "        return pd.Series({\"avg_effort\": avg_effort, \"outcome_rate\": outcome_rate})\n",
    "\n",
    "    eo_per_step = []\n",
    "    for step, effort in efforts:\n",
    "        ai_step = agents_info.copy()\n",
    "        ai_step[\"effort\"] = effort\n",
    "        ai_step.dropna(subset=\"effort\", inplace=True)    \n",
    "        ai_step[\"effort_bins\"] = pd.cut(ai_step[\"effort\"], bins)\n",
    "        ai_step[\"outcome\"] = environment.metadata_[step][\"outcome\"]\n",
    "        \n",
    "        eo = ai_step.groupby([\"groups\", \"effort_bins\"], group_keys=True).apply(extract_info)\n",
    "        eo = eo.reset_index().groupby(\"groups\", group_keys=True).apply(lambda df: (df[\"outcome_rate\"] * df[\"avg_effort\"]).sum() / df[\"avg_effort\"].sum())\n",
    "        eo = eo.to_frame(step).T\n",
    "        eo[\"eo_total\"] = eo[not_advantaged] / eo[advantaged_pop]\n",
    "        eo_per_step.append(eo)\n",
    "    \n",
    "    eo_per_step = pd.concat(eo_per_step)\n",
    "    \n",
    "    disparates[\"avg_EO\"] = eo_per_step[\"eo_total\"].mean()\n",
    "    \n",
    "    if return_eo_only:\n",
    "        return eo_per_step\n",
    "    \n",
    "    return disparates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce3255-eb8d-49c9-90de-3fc78ab980db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fairness_metrics_per_time_step(environment):\n",
    "    # Get groups\n",
    "    groups = pd.concat([environment.metadata_[step][\"X\"][\"groups\"] for step in environment.metadata_.keys()])\n",
    "    groups = groups[~groups.index.duplicated(keep='last')].sort_index()\n",
    "\n",
    "    # Get time for recourse\n",
    "    agents_info = environment.analysis.agents_info()\n",
    "    agents_info = pd.concat([agents_info, groups], axis=1)\n",
    "    agents_info[\"time_for_recourse\"] = agents_info[\"favorable_step\"] - agents_info[\"entered_step\"]\n",
    "\n",
    "    # Get fairness analysis\n",
    "    fairness_analysis = agents_info.dropna().groupby(\"groups\").mean()\n",
    "    success_rates = environment.analysis.success_rate(filter_feature=\"groups\")\n",
    "    sns.lineplot(success_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee3130-6a1a-4f43-8a0c-83350ad738a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fairness_metrics_overall_visualizations(environment):\n",
    "    # Get groups\n",
    "    groups = pd.concat([environment.metadata_[step][\"X\"][\"groups\"] for step in environment.metadata_.keys()])\n",
    "    groups = groups[~groups.index.duplicated(keep='last')].sort_index()\n",
    "\n",
    "    # Get time for recourse\n",
    "    agents_info = environment.analysis.agents_info()\n",
    "    agents_info = pd.concat([agents_info, groups], axis=1)\n",
    "    agents_info[\"time_for_recourse\"] = agents_info[\"favorable_step\"] - agents_info[\"entered_step\"]\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # ETR - Effort to recourse\n",
    "    ai_etr = agents_info.dropna(subset=\"favorable_step\")\n",
    "    ai_etr = ai_etr[ai_etr[\"n_adaptations\"]!=0]\n",
    "\n",
    "    ai_etr[\"total_effort\"] = ai_etr[\"final_score\"] - ai_etr[\"original_score\"]\n",
    "    etr = ai_etr.groupby(\"groups\").mean()[\"total_effort\"]\n",
    "    results[\"etr_disparity\"] = etr.loc[0] / etr.loc[1]    \n",
    "    \n",
    "    # TTR\n",
    "    ttr = ai_etr.groupby(\"groups\").mean()[\"time_for_recourse\"]\n",
    "    results[\"disparate_ttr\"] = ttr.loc[0] - ttr.loc[1]\n",
    "\n",
    "    sns.boxplot(data=ai_etr, x=\"groups\", y=\"total_effort\")\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(data=ai_etr, x=\"groups\", y=\"time_for_recourse\")\n",
    "    plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494ffe8-9bad-45a4-97c1-2e9c2806862f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fairness_metrics_overall(environment):\n",
    "    # Get groups\n",
    "    groups = pd.concat([environment.metadata_[step][\"X\"][\"groups\"] for step in environment.metadata_.keys()])\n",
    "    groups = groups[~groups.index.duplicated(keep='last')].sort_index()\n",
    "\n",
    "    # Get time for recourse\n",
    "    agents_info = environment.analysis.agents_info()\n",
    "    agents_info = pd.concat([agents_info, groups], axis=1)\n",
    "    agents_info[\"time_for_recourse\"] = agents_info[\"favorable_step\"] - agents_info[\"entered_step\"]\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # ETR - Effort to recourse\n",
    "    ai_etr = agents_info.dropna(subset=\"favorable_step\")\n",
    "    ai_etr = ai_etr[ai_etr[\"n_adaptations\"]!=0]\n",
    "\n",
    "    ai_etr[\"total_effort\"] = ai_etr[\"final_score\"] - ai_etr[\"original_score\"]\n",
    "    etr = ai_etr.groupby(\"groups\").mean()[\"total_effort\"]\n",
    "    results[\"etr_disparity\"] = etr.loc[0] / etr.loc[1]    \n",
    "    \n",
    "    # TTR\n",
    "    ttr = ai_etr.groupby(\"groups\").mean()[\"time_for_recourse\"]\n",
    "    results[\"disparate_ttr\"] = ttr.loc[0] - ttr.loc[1]\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596270bc-1ab5-416a-a583-65172cf58829",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiments (Standard Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20b0dd-fbbe-4b7c-ab81-36ae0038f159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, y = biased_data_generator(N_AGENTS, n_continuous=N_CONTINUOUS, bias_factor=BIAS_FACTOR, scaler=scaler, random_state=rng)\n",
    "categorical = [\"groups\"]\n",
    "\n",
    "model = IgnoreGroupLR(categorical, random_state=RNG_SEED).fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5e4ae-6140-4194-bbb9-03ed7ac404de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(model.predict_proba(df)[:,0],bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c84d6-3d0a-41ac-a0f5-51ff3e202636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Original classes:\\n\", df.groupby([\"groups\", y]).size())\n",
    "print(\"Predicted classes:\\n\", df.groupby([\"groups\", model.predict(df)]).size())\n",
    "df.pivot(columns=\"groups\")[\"f0\"].plot(kind=\"hist\", stacked=False, bins=10, alpha=0.5, title=\"f0\")\n",
    "df.pivot(columns=\"groups\")[\"f1\"].plot(kind=\"hist\", stacked=False, bins=10, alpha=0.5, title=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ffeed-ce10-41c4-a5fc-69b1237ac67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.min(), df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13af034-9904-4a77-9602-210bd3ee4954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the necessary components to run simulation\n",
    "recourse = NFeatureRecourse(model, categorical=[\"groups\"], immutable=[\"groups\"])# , random_state=RNG_SEED)\n",
    "recourse.set_actions(df)\n",
    "recourse.action_set_.lb = [-0.1, -0.1, 0]\n",
    "recourse.action_set_.ub = [1.1, 1.1, 1]\n",
    "\n",
    "environment = FairEnvironment(\n",
    "    X=df,\n",
    "    recourse=recourse,\n",
    "    group_feature=\"groups\",\n",
    "    data_source_func=env_biased_data_generator,\n",
    "    threshold=N_LOANS,\n",
    "    threshold_type=\"absolute\",\n",
    "    adaptation=ADAPTATION,\n",
    "    behavior_function=\"continuous_constant\",\n",
    "    growth_rate=NEW_AGENTS,\n",
    "    growth_rate_type=\"absolute\",\n",
    "    random_state=RNG_SEED,\n",
    ")\n",
    "\n",
    "environment.simulate(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40530223-2201-431f-be8d-6bbe38c99fca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization and analysis (Standard Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e9860-5eb5-453e-a20e-245854a42bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "environment.plot._favorable = ListedColormap([\"#40b27f\", \"green\"])\n",
    "environment.plot._unfavorable = ListedColormap([\"#51a3ef\", \"blue\"])\n",
    "environment.plot._previous = ListedColormap([\"#be4d65\", \"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed65d9e-e1bf-4c71-b8b7-19186e37df69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment.plot.agent_scores(color_feature=\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e04359-b2ef-4842-b2b6-7ffaab32b802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = environment.plot.scatter(10, color_feature=\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda8ae7-6e43-4733-90d8-265caf29effc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fairness_metrics_per_time_step(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7b243-aceb-4ce9-abdb-ce1253720017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_metrics_overall_visualizations(environment)\n",
    "# Boxplots for different qualification values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864a60e-49b8-4717-9507-ca5a7f279725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fairness_metrics(environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c8ad8-0537-448b-a466-13c25b45c47c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Draft code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ed11e-6df4-4984-8b31-900456695d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb2290-4600-44b4-ac62-e32115a4a886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fair_grouped = df_fair.groupby([\"groups\", \"effort_bins\"]).mean()\n",
    "df_fair_grouped[\"size\"] = df_fair.groupby([\"groups\", \"effort_bins\"]).size()\n",
    "# df_fair_grouped.loc[1]\n",
    "# df_fair_grouped.loc[0]\n",
    "df_fair_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a5775-7143-4941-93ee-77cf702125ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment.metadata_[5][\"threshold_index\"]\n",
    "environment.metadata_[5][\"effort\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f0c5e-3099-440e-b376-0c03e11b9a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1def46d-d945-4e2c-ae4a-d4063d303e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = Counter(df[\"groups\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57d8c4-4fd3-4f7b-820e-46d912e4c702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(environment.X_.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d59ebf-1b63-40bd-9c97-82f250c71c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(environment.get_all_agents().groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
